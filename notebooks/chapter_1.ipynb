{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Exploratory Data Analysis\n",
    "\n",
    "    Overview: This chapter focuses on the first step of any data science project: epxloring the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "Two types of data structures:\n",
    "* Unstructured data: Images, videos, Emails, Audio files\n",
    "* Structured data: Relational databases, Spreadsheets, data tables (CSV, TSV), XML & JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Types***\n",
    "\n",
    "There are two basic types of structure data: numeric and categorical.\n",
    "\n",
    "* Numeric: Data expressed on a numeric scale\n",
    "    * Continuous: Data that can take on any value in an interval \n",
    "        * Synonyms: interval, float, numeric\n",
    "        * Examples: Time, meters, miles\n",
    "    * Discrete: Data that can take only integer values\n",
    "        * Synonyms: integer, count\n",
    "        * Examples: Age, Number of students in a class, Number of rooms in a house\n",
    "\n",
    "* Categorical: Data taht can take on only a specific set of values representing a set of possible categories (Synonyms: enums, enumerated, factors, nominal)\n",
    "    * Binary: A special case of categorical data with just two categories of values\n",
    "        * Synonyms: dichotomous, logical, indicator, boolean\n",
    "        * Examples: 0 or 1, True or False\n",
    "    * Ordinal: Categorical data that has an explicit ordering.\n",
    "        * Synonyms: ordered factor\n",
    "        * Examples: (Red, Green, or Blue), (Large, Medium, Small), (Cat, Dog, Mouse), Movie ratings, levels of pain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Typing in Software***\n",
    "\n",
    "Different software will handle data types differently. As a result, it's important to know your software and how it handles data types so that practitioners can appropriately conduct analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Key Terms for Rectangular Data***\n",
    "\n",
    "Data Frame\n",
    "* Rectangular data (like a spreadsheet) is the basic data structure for statistical and machine learning models.\n",
    "\n",
    "Feature\n",
    "* A column within a table is commonly referred to as a feature\n",
    "\n",
    "Outcome\n",
    "* Many data science projects involve predicting an *outcome* - often a yes/no outcome. The features are sometimes used to predict the *outcome* in an experiment or a study.\n",
    "* Synonyms: dependent variable, response, target, otuput\n",
    "\n",
    "Records\n",
    "* A row within a table is commonly referred to as a *record*.\n",
    "* Synonyms: case, example, instance, observation, pattern, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nonrectangular Data Structures***\n",
    "* Time-series data\n",
    "* Spacial data structures (mapping and location analytics)\n",
    "* Graph data structures (physical, social, and abstract relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates of Location\n",
    "Estimates of location are variables with measured or coutn data that might have thousands of distinct values. A basic step in exploring your data is getting a \"typical value\" for each feature (variable): an estimate of where most of the data is located (i.e., its central tendancy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Terms for Estimates of Location**\n",
    "\n",
    "Mean\n",
    ">The sum of all values divided by the number of values.\n",
    ">>Synonym: average\n",
    "\n",
    "Weighted mean\n",
    ">The sum of all values times a weight divided by the sum of the weights.\n",
    ">>Synonym: weighted average\n",
    "\n",
    "Median\n",
    ">The value such that one-half of the data lies above and below.\n",
    ">>Synonym: 50th percentile\n",
    "\n",
    "Percentile\n",
    ">The value such that *P* percent of the data lies below.\n",
    ">>Synonym: quantile\n",
    "\n",
    "Weighted median\n",
    ">The value such that one-half of the sum of the weights lies above and below the sorted data.\n",
    "\n",
    "Trimmed mean\n",
    ">The average of all values after dropping a fixed number of extreme values.\n",
    ">>Synonym: truncated mean\n",
    "\n",
    "Robust\n",
    ">Not sensitive to extreme values.\n",
    ">>Synonym: resistant\n",
    "\n",
    "Outlier\n",
    ">A data value that is very different from most of the data.\n",
    ">>Synonym: extreme value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean**\n",
    "\n",
    "$\n",
    "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n",
    "$\n",
    "\n",
    "The most basic estimate of location is the mean, or *average* value. The mean is the sum of all values divided by the number of values. Consider the following set of numbers: {3, 5, 1, 2}. \n",
    "\n",
    "The mean is \n",
    "= (3 + 5 + 1 + 2) / 4 \n",
    "= 11 / 4\n",
    "= 2.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trimmed mean**\n",
    "\n",
    "$ \\bar{x} = \\dfrac{\\displaystyle\\sum_{i=p+1}^{\\,n-p} x_{(i)}}{n - 2p} $\n",
    "\n",
    "A variation of the mean is a *trimmed mean*, which you calculate by dropping a fixed number of sorted values at each end and then taking an average of the remaining values. Representing the sorted values by $x_{(1)}, x_{(2)}... x_{(n)}$ where $x_{(1)}$ is the smallest value and $x_{(n)}$ is the largest.\n",
    "\n",
    "A trimmed mean eliminates the influence of extreme values. For example, in international diving the top and bottom scores from five judges are dropped, and the final score is the average of the scores from the three remaining judges. This makes it difficult for a single judge to manipulate the score, perhaps to favor their country's contestant. Trimmed means are widely used, and in many cases are preferable to using the ordinary mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Mean**\n",
    "\n",
    "$ \\bar{x}_w = \\dfrac{\\displaystyle\\sum_{i=1}^{n} w_i x_i}{\\displaystyle\\sum_{i=1}^{n} w_i} $\n",
    "\n",
    "Another type of mean is a *weighted mean*, which you calculate by multiplying each data value $x_{(i)}$ by a user-specified weight $w_{(i)}$ and dividing their sum by the sum of the weights. \n",
    "\n",
    "There are two (2) main motivations for using a weighted mean:\n",
    "1. Some values are intrinsically more variable than others, and highly variable observations are given a lower weight. For example, if we are taking the average from multiple sensors and one of the sensors is less accurate, then we might downweight the data from that sensor.\n",
    "2. The data collected does not equally represent the different groups that we are interested in measuring. For example, because of the way an online experiment was conducted, we may not have a set of data that accurately reflects all groups in the user base. To correct that, we can give a higher weight to the values from the groups that were underrepresented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median and Robust Estimates**\n",
    "\n",
    "The *median* is the middle number on a sorted list of the data. If there is an even number of data values, the middle value is one that is not actually in the data set, but rather the average of the two values that divide the sorted data into upper and lower halves. Compared to the mean, which uses all observations, the median depends only on the values in the center of the sorted data. While this might seem to be a disadvantage, since the mean is much more sensitive to the data, there are many instances in which the median is a better metric for estimating location. Let's say we want to look at typical household incomes in neighborhoods around Lake Washington in Seattle. In comparing the Medina neighborhood to the Windermere neighborhood, using the mean would produce very different results because Bill Gates lives in Medina. If we use the median, it won't matter how rich Bill Gates is - the position of the middle observation will remain the same.\n",
    "\n",
    "For the same reasons one uses a weighted mean, it's also possible to compute a *weighted median*. As with the median, we first sort the data, although each data value has an associated weight. Instead of the middle number, the weighted median is a value such that the sum of the weights is equal for the lower and upper halves of the sorted list. Like the median, the weighted median is robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**\n",
    "\n",
    "The median is referred to as a *robust* estimate of location since it's not influenced by *outliers* (extreme cases) that could skew the results. An outlier is any value that is very distant from the other values in a data set. \n",
    "\n",
    "An outlier itself doesn't make a data value invalid or erroneous (like the Bill Gates example). Still, outliers are often the result of data errors such as mixing data of different units (kilometers vs. meters) or bad readings from a sensor. When outliers are the result of bad data, the mean will result in a poor location estimate, while the median will still be valid. In any case, outliers should be identified and are usually worthy of further investigation.\n",
    "\n",
    "> Anomaly Detection\n",
    ">>In contrast to typical data analysis, where outliers are somtimes informative and sometimes a nuisance, in *anomaly detection* the points of interest are the outliers, and the greater mass of data serves primarily to define the \"normal\" against which anomalies are measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Murder.Rate</th>\n",
       "      <th>Abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>5.7</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>710231</td>\n",
       "      <td>5.6</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>6392017</td>\n",
       "      <td>4.7</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2915918</td>\n",
       "      <td>5.6</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>37253956</td>\n",
       "      <td>4.4</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Population  Murder.Rate Abbreviation\n",
       "0     Alabama     4779736          5.7           AL\n",
       "1      Alaska      710231          5.6           AK\n",
       "2     Arizona     6392017          4.7           AZ\n",
       "3    Arkansas     2915918          5.6           AR\n",
       "4  California    37253956          4.4           CA"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df = pd.read_csv(\"/Users/brian.v.nguyen/projects/practical_statistics_for_data_scientists/data/state.csv\")\n",
    "state_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean, trimmed mean, and median for the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 6162876.3\n",
      "Median: 4436369.5\n",
      "Trimmed Average: 4783697.125\n"
     ]
    }
   ],
   "source": [
    "avg = state_df['Population'].mean()\n",
    "med = state_df['Population'].median()\n",
    "trimmed_avg = stats.trim_mean(state_df['Population'], 0.1)\n",
    "\n",
    "print(f\"Average: {avg}\")\n",
    "print(f\"Median: {med}\")\n",
    "print(f\"Trimmed Average: {trimmed_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the weighted average murder rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wquantiles # pip3 install wquantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Avg. Murder Rate using NumPy: 4.445833981123393\n",
      "Weighted Avg. Murder Rate using wquantiles: 4.4\n"
     ]
    }
   ],
   "source": [
    "np_weighted_avg_murder_rate = np.average(\n",
    "    state_df['Murder.Rate'],\n",
    "    weights=state_df['Population']\n",
    "    )\n",
    "\n",
    "wquantiles_weighted_avg_murder_rate = wquantiles.median(\n",
    "    state_df['Murder.Rate'],\n",
    "    weights=state_df['Population']\n",
    "    )\n",
    "\n",
    "print(f\"Weighted Avg. Murder Rate using NumPy: {np_weighted_avg_murder_rate}\")\n",
    "print(f\"Weighted Avg. Murder Rate using wquantiles: {wquantiles_weighted_avg_murder_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates of Variability\n",
    "\n",
    "Location is just one dimension of summarizing a feature. A second dimension, variability, also referred to as *dispersion*, measures whether the data values are tightly clustered or spread out. At the heart "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
